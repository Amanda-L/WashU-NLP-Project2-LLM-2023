{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEp_Gfvve7Wb"
      },
      "source": [
        "# **Assignment 2 - Language Models**\n",
        "#### **Due: September 28, 2023, 11:59PM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0mQO36cfN_9"
      },
      "source": [
        "### **Notes**\n",
        "\n",
        "### **Introduction**\n",
        "\n",
        "Welcome to CSE 527A. Each assignment will contain two parts: a written and coding portion. The coding portion for each homework assignment will be delivered through a Colaboratory notebook such as this one. Please use as many code and markdown cells to run and explain all the steps you took in order to answer each question for each problem. Please keep in mind the collaboration policy as specified in the Academic Integrity section of the syllabus and cite all external sources and/or collaborators.\n",
        "\n",
        "### **Comments/Documentation**\n",
        "\n",
        "Please follow PEP 8 style guidelines (https://peps.python.org/pep-0008/) for commenting your code. Furthermore, please remember to manually save your work once in a while. If you are connected to a hosted runtime that if for whatever reason it disconnects you will have to rerun all connected code cells.\n",
        "\n",
        "### **Getting Started**\n",
        "\n",
        "In order to compile code efficiently, enable GPU support.\n",
        "\n",
        "To access a GPU, go to `Edit->Notebook settings` and in the `Hardware accelerator` dropdown choose `GPU`.\n",
        "As soon as you run a code cell, you will be connected to a cloud instance with a GPU.\n",
        "Try running the code cell below to check that a GPU is connected (select the cell then either click the play button at the top left or press `Ctrl+Enter` or `Shift+Enter`).\n",
        "\n",
        "The free version of Google Colab will provide the necessary hardware for this course. Please keep in mind the RAM and Disk Space that you are allocated and that you are not given an infinite active runtime.\n",
        "\n",
        "### **Submission Instructions**\n",
        "\n",
        "We will use Gradescope for assignment submission. Submit the written and code portions of the assignment to the respective assignments. **Please note if notebook output is cleared, you will receive a 0**. To download this notebook, go to `File->Download .ipynb`.\n",
        "\n",
        "When submitting your ipython notebooks, make sure everything runs correctly if the cells are executed in order starting from a fresh session.  Note that just because a cell runs in your current session doesn't mean it doesn't rely on code that you have already changed or deleted.\n",
        "\n",
        "Note that Gradesope will allow you to submit multiple times before the deadline, and we will use the latest submission for grading."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hrjsO05g9PS"
      },
      "source": [
        "## **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNW-H4F3hNUB",
        "outputId": "3ab72e70-b465-4012-c7e5-1c565322b5f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive # one option to load datasets\n",
        "from google.colab import files\n",
        "drive.mount('/content/gdrive')\n",
        "!nvidia-smi -L # check if using GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWF6TvxkUbZ0"
      },
      "outputs": [],
      "source": [
        "# various imports you might find useful, feel free to import additional packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch import Tensor\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "from torch import optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KppGhZ5ZdGrb",
        "outputId": "e8491c68-70ca-40c8-84fa-4cc213fba014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDvzHG_RdGrc"
      },
      "outputs": [],
      "source": [
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "trainset = load_dataset(\"wikitext\", name=\"wikitext-2-v1\", split=\"train\")\n",
        "valset = load_dataset(\"wikitext\", name=\"wikitext-2-v1\", split=\"validation\")\n",
        "testset = load_dataset(\"wikitext\", name=\"wikitext-2-v1\", split=\"test\")\n",
        "\n",
        "# Preprocess text\n",
        "punctuation = list(\"~!@#$%^&*()_+`{}|\\[\\]\\:\\\";\\-\\\\\\='<>?,./，。、《》？；：‘“{【】}|、！@#￥%……&*（）——+=-\")\n",
        "def preprocess(dataset):\n",
        "  data = []\n",
        "  for text in dataset['text']:\n",
        "    # Ignore emtpy sentences\n",
        "    if text == '':\n",
        "      continue\n",
        "    # Remove puncutation and unknown tokens\n",
        "    tokens = [t for t in text.split() if t != '' and t not in punctuation and t != '<unk>']\n",
        "    data.append(tokens)\n",
        "  return data\n",
        "traindata = preprocess(trainset)\n",
        "valdata = preprocess(valset)\n",
        "testdata = preprocess(testset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhCuafE5UCmK"
      },
      "source": [
        "# Problem 1\n",
        "(Eisenstein Ch. 6) Using the Pytorch library, train an LSTM language model from the same Wikitext training corpus you used in problem 1. After each epoch of training, compute its perplexity on the Wikitext validation corpus. Stop training when the perplexity stops improving.\n",
        "\n",
        "1. Fully describe your model architecture, hyperparameters, and experimental procedure.\n",
        "2. After each epoch of training, compute your LM’s perplexity on the development data. Plot the development perplexity against # of epochs. Additionally, compute and report the perplexity on test\n",
        "data.\n",
        "\n",
        "**NOTE:** This may take some time, so you should start early. Also, you should use a GPU. When using PyTorch, you can move your model and data to the GPU with the following commands:\n",
        "\n",
        "```\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # This is defined for you\n",
        "model.to(device)\n",
        "x = x.to(device)\n",
        "```\n",
        "\n",
        "**The PyTorch documentation is very good; I recommend reading it.**\n",
        "Start here: https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
        "\n",
        "Good luck, and post on Piazza if you have any questions or see any errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFj6JztEWZtD"
      },
      "source": [
        "### Starting Point\n",
        "First, find the distribution of sentence length to decide the max-length for training RNN models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpvKOjl1WRv-"
      },
      "outputs": [],
      "source": [
        "# Your code goes here\n",
        "# train data is a list with a bunch of sentences in list, the total sentences are 23767\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "sentence_length = []\n",
        "\n",
        "for sentence_list in traindata:\n",
        "    sentence_length.append(len(sentence_list))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "B9JoFP5H7vgR",
        "outputId": "2697bd70-22a1-450f-8a48-45044e733483"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum length of sentence is:  628\n",
            "Average length of sentence is:  72.52333066857408\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "plt.hist(sentence_length, bins = 60)\n",
        "print(\"Maximum length of sentence is: \", np.max(sentence_length))\n",
        "print(\"Average length of sentence is: \", np.mean(sentence_length))\n",
        "\n",
        "plt.xlabel('sentence length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ3N_JiCdGre"
      },
      "source": [
        "Based on the above, choose the max-length for training RNN models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u39NZ4xJWN5d"
      },
      "outputs": [],
      "source": [
        "# TODO: select these values based on the above.\n",
        "# MAXLEN = 628 # Maximum length of the input sentences\n",
        "MAXLEN =  268 # 628 is running foreever and the performance is not good, so I changed it to 256 follwed by the comments on Piazza\n",
        "batch_size = 32 # For training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZGUmwtlWozK"
      },
      "source": [
        "Now, run the below to load the data.\n",
        "\n",
        "*Note: This is done for you; there is no code to write here*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPJjSIbMUSik",
        "outputId": "dfafed31-dc72-4b42-a019-8306e0ceba20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([23767, 268])\n",
            "torch.Size([2461, 268])\n",
            "torch.Size([2891, 268])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "20598"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Covert list of tokens to list of token ids\n",
        "def indexData(data, word2index=None):\n",
        "    \"\"\"\n",
        "    data: corpus - list of list of tokens\n",
        "    word2index: None before training\n",
        "    \"\"\"\n",
        "    if word2index is None:\n",
        "        freqs = {}\n",
        "        for in_list in data:\n",
        "            for w in in_list:\n",
        "              freqs[w] = freqs.get(w, 0) + 1\n",
        "        vocab = [w for w, c in freqs.items() if c > 5] # Ignore words of low frequency\n",
        "        word2index = {word: index + 1 for index, word in enumerate(vocab)}\n",
        "        word2index['<pad>'] = 0\n",
        "    data_ids = []\n",
        "    for seq in data:\n",
        "      data_ids.append([word2index[w] if w in word2index else 0 for w in seq[:MAXLEN]]) # Use maxlen to define the max length of input\n",
        "    return data_ids, word2index\n",
        "\n",
        "\n",
        "# Convert list of token ids to padding sequences\n",
        "def genSeq(data_id):\n",
        "    inputs = [torch.LongTensor(seq) for seq in data_id]\n",
        "    inputs_padded = pad_sequence(sequences=inputs, batch_first=True, padding_value=0)\n",
        "    return inputs_padded\n",
        "\n",
        "# Get dataloader for pytorch models\n",
        "def gendataloader(data_id, batch_size, shuffle=False):\n",
        "    inputs_padded = genSeq(data_id)\n",
        "    print(inputs_padded.shape)\n",
        "    t_dataset = TensorDataset(inputs_padded)\n",
        "    return DataLoader(dataset=t_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "traindata_id, word2index = indexData(traindata, word2index=None)\n",
        "valdata_id, word2index = indexData(valdata, word2index=word2index)\n",
        "testdata_id, word2index = indexData(testdata, word2index=word2index)\n",
        "\n",
        "train_loader = gendataloader(traindata_id, batch_size, shuffle=True)\n",
        "val_loader = gendataloader(valdata_id, batch_size, shuffle=False)\n",
        "test_loader = gendataloader(testdata_id, batch_size, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Use 'cpu' if a GPU is not available.\n",
        "\n",
        "# Show vocabulary size\n",
        "vocab_size = len(word2index)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNOGgLzRWvki"
      },
      "source": [
        "### Creating the Model\n",
        "Next, create an LSTM with PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRku1jWlXKUX"
      },
      "outputs": [],
      "source": [
        "# answer reference from: https://wandb.ai/sauravmaheshkar/LSTM-PyTorch/reports/Using-LSTM-in-PyTorch-A-Tutorial-With-Examples--VmlldzoxMDA2NTA5\n",
        "# answer reference from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "# answer reference from pytorch documentation: https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
        "\n",
        "class lmLSTM(nn.Module):\n",
        "    def __init__(self,  vocab_size, embed_dim, hidden_dim, num_layers=1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            vocab_size: size of the vocabulary.\n",
        "            embed_dim: size of the word embedding.\n",
        "            hidden_dim: size of the hidden state of the LSTM.\n",
        "            num_layers: number of layers in the LSTM.\n",
        "\n",
        "        \"\"\"\n",
        "        super(lmLSTM, self).__init__()\n",
        "        # Your code goes here\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "        # LSTM layers\n",
        "        self.lstm = nn.LSTM(input_size=embed_dim,\n",
        "                            hidden_size=hidden_dim,\n",
        "                            num_layers=num_layers,\n",
        "                            batch_first=True)\n",
        "\n",
        "        #  Linear layer for output\n",
        "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def init_state(self, batch_size):\n",
        "        \"\"\" Initialize states of LSTM\n",
        "\n",
        "        This is the first step of the forward pass. The LSTM has two states,\n",
        "        the hidden state and the cell state. These are initialized here and\n",
        "        put to the right device.\n",
        "\n",
        "        Args:\n",
        "            batch_size: size of the batch.\n",
        "\n",
        "        Returns:\n",
        "            initialized states.\n",
        "\n",
        "        \"\"\"\n",
        "        # Your code goes here\n",
        "\n",
        "        # Initialize hidden state and cell state\n",
        "        # Or adding .cuda behind\n",
        "\n",
        "        # h_0 = (num_layers, batch size, hidden size)\n",
        "        hidden_state = torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size, device = device)\n",
        "\n",
        "        # c_0 = (num_layers, batch size, hidden size)\n",
        "        cell_state = torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size, device = device)\n",
        "\n",
        "        # as a tuple\n",
        "        return (hidden_state, cell_state)\n",
        "\n",
        "    def detach_states(self, states):\n",
        "        \"\"\"Detach states of LSTM\n",
        "\n",
        "        This is the last step of the forward pass. The LSTM has two states,\n",
        "        the hidden state and the cell state. These are detached because the\n",
        "        LSTM is trained using truncated backpropagation through time.\n",
        "\n",
        "        Args:\n",
        "            states: the LSTM states to detach.\n",
        "\n",
        "        Returns:\n",
        "            detached states.\n",
        "\n",
        "        \"\"\"\n",
        "        # Your code goes here\n",
        "        # Detach both hidden and cell states\n",
        "        detached_hc = states[0].detach(), states[1].detach()\n",
        "        return detached_hc\n",
        "\n",
        "# answer reference: https://www.educative.io/answers/how-to-build-an-lstm-model-using-pytorch\n",
        "\n",
        "    def forward(self, inputs, states):\n",
        "        \"\"\"Defines the computation performed at every call.\n",
        "\n",
        "        Args:\n",
        "            inputs: batch of input sentences.\n",
        "            states: the LSTM states.\n",
        "\n",
        "        Returns:\n",
        "            logits: the output logits.\n",
        "            states: the updated states of the LSTM.\n",
        "\n",
        "        \"\"\"\n",
        "        # Your code goes here\n",
        "        embeddings = self.embedding(inputs)\n",
        "\n",
        "        lstm_output, new_c_states = self.lstm(embeddings, states)\n",
        "\n",
        "        # y_pred = logits = the raw, unnormalized predictions that a model generates\n",
        "        y_pred = self.linear(lstm_output)\n",
        "\n",
        "        return y_pred, new_c_states\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4futSebdGrf"
      },
      "source": [
        "After creating the model, let's define reasonable hyperparameters as well as the training procedure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4BenU4fdGrf"
      },
      "outputs": [],
      "source": [
        "# TODO: update Hyperparameters\n",
        "embed_dim = 128 # Embedding layer size\n",
        "hidden_dim = 64 # (LSTM) hidden layer size\n",
        "num_layers= 2 # Number of LSTM layers\n",
        "num_epoch = 5 # The maximum training epochs\n",
        "learning_rate = 0.0001 # For training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zxe3EcTdGrf"
      },
      "source": [
        "Initialize the model and any other variables you need. (Change the values from ```None``` to your code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnUiQaQKdGrf",
        "outputId": "5ab77e61-16a3-47d0-a673-458a3cc094fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lmLSTM(\n",
            "  (embedding): Embedding(20598, 128)\n",
            "  (lstm): LSTM(128, 64, num_layers=2, batch_first=True)\n",
            "  (linear): Linear(in_features=64, out_features=20598, bias=True)\n",
            ")\n",
            "Number of trainable parameters: 4058358\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Use 'cpu' if a GPU is not available.\n",
        "\n",
        "\n",
        "# Initialization of the model\n",
        "\n",
        "model = lmLSTM(vocab_size, embed_dim, hidden_dim, num_layers)\n",
        "\n",
        "# Move model to the right device\n",
        "model.to(device)\n",
        "\n",
        "# Initialize optimizer and loss function\n",
        "\n",
        "loss_funct = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizers specified in the torch.optim package\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "# model architecture\n",
        "print(model)\n",
        "\n",
        "# number of trainable parameters\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of trainable parameters: {num_params}')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjM7jPlJdGrf"
      },
      "source": [
        "Let's define perplexity to use in our analysis.\n",
        "\n",
        "PPL = exp(-1/N * Σ(log P(x_i)))\n",
        "\n",
        "\n",
        "To compute the perplexity based on losses:\n",
        "\n",
        "\n",
        "1.   Iterate through the data.\n",
        "2.   For each input sequence, compute the model's predicted logits.\n",
        "3. Calculate the loss using the predicted logits and the ground truth labels.\n",
        "4. Keep track of the total loss.\n",
        "5. After processing all sequences, compute the average loss.\n",
        "6. Use the average loss to calculate the perplexity.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZFy4racdGrf"
      },
      "outputs": [],
      "source": [
        "# answer reference from: https://towardsdatascience.com/perplexity-in-language-models-87a196019a94\n",
        "# answer reference from: https://medium.com/@priyankads/perplexity-of-language-models-41160427ed72\n",
        "\n",
        "# Compute perplexity based on losses\n",
        "def perplexity(data, model):\n",
        "    \"\"\"Compute perplexity of the data.\n",
        "\n",
        "    Args:\n",
        "        data: the data to compute the perplexity of.\n",
        "        model: the language model.\n",
        "\n",
        "    Returns:\n",
        "        perplexity of the data (float)\n",
        "\n",
        "    \"\"\"\n",
        "    print(\"model:\",model)\n",
        "    with torch.no_grad():\n",
        "        # Your code goes here\n",
        "        total_loss = 0.0\n",
        "        total_tokens = 0\n",
        "\n",
        "        average_loss_list = []\n",
        "        for batch in data:\n",
        "            inputs = batch[0].to(device)\n",
        "            labels = torch.cat([inputs[:, 1:], torch.zeros(inputs.shape[0], 1).long().to(device)], dim=1)\n",
        "\n",
        "            states = model.init_state(inputs.size()[0])\n",
        "            states = model.detach_states(states)\n",
        "            y_pred, new_c = model(inputs, states)\n",
        "\n",
        "            # ensure that the dimensions of y_pred and labels align properly for computing the loss\n",
        "            y_pred = y_pred.view(-1, y_pred.size(2))\n",
        "            labels= labels.view(-1)\n",
        "\n",
        "            loss_value = loss_funct(y_pred, labels).item()\n",
        "\n",
        "            total_loss += loss_value / batch[0].size()[0]\n",
        "\n",
        "            average_loss_list.append(total_loss)\n",
        "\n",
        "        average_loss = sum(average_loss_list) / len(average_loss_list)\n",
        "        perplexity = np.exp([average_loss])\n",
        "\n",
        "        return perplexity\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC6khYDZdGrf"
      },
      "source": [
        "### Training the Model\n",
        "Now set up the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXviINQrdGrf"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "val_pps = [] # List of perplexities on the validation data\n",
        "def training():\n",
        "\n",
        "  \"\"\"Training of the model. Describe what happens in the training loop.\n",
        "\n",
        "  The model is trained using backpropagation through time. The\n",
        "  states of the LSTM are detached at the end of each epoch.\n",
        "\n",
        "  There are three main steps in the training loop:\n",
        "  1. Get the data and run the model\n",
        "  2. Update the parameters\n",
        "  3. Save the loss and compute the perplexity on the validation data;\n",
        "    if the perplexity is higher than the previous epoch, return the model.\n",
        "\n",
        "    Make sure to put the model in train mode at the beginning of each epoch and\n",
        "    put the model in eval mode at the beginning of each evaluation step.\n",
        "\n",
        "  Returns:\n",
        "      the trained model.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  lowest_perplexity_score = float('inf')\n",
        "\n",
        "\n",
        "  for epoch in tqdm(range(num_epoch), desc=\"Epochs\"):\n",
        "      model.train()\n",
        "      # print(tf.test.gpu_device_name())\n",
        "      # Initialize states\n",
        "\n",
        "      states = model.init_state(batch_size)\n",
        "\n",
        "\n",
        "      for batch in train_loader:\n",
        "\n",
        "\n",
        "          inputs = batch[0].to(device)\n",
        "          if inputs.size()[0] != batch_size:\n",
        "            continue\n",
        "\n",
        "          # Preparing the target labels for the model by taking each input sequence, removing the first element, and appending a column of zeros\n",
        "          # To align the model's predictions/logits with the actual targets for training.\n",
        "          labels = torch.cat([inputs[:, 1:], torch.zeros(inputs.shape[0], 1).long().to(device)], dim=1)\n",
        "\n",
        "          states = model.detach_states(states)\n",
        "\n",
        "\n",
        "          # Make predictions for this batch\n",
        "          y_pred, new_c = model(inputs, states)\n",
        "\n",
        "          # ensure that the dimensions of y_pred and labels align properly for computing the loss\n",
        "          y_pred = y_pred.view(-1, y_pred.size(2))\n",
        "          labels= labels.view(-1)\n",
        "\n",
        "          # Zero your gradients for every batch!\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Compute the loss\n",
        "          loss = loss_funct(y_pred, labels)\n",
        "          loss.backward()\n",
        "\n",
        "          # Adjust learning weights\n",
        "          optimizer.step()\n",
        "\n",
        "      val_perplexity = perplexity(val_loader, model)\n",
        "      val_pps.append(val_perplexity)\n",
        "      print(f\"Epochs: {epoch}\")\n",
        "      print(f\"Validation Perplexity: {val_perplexity}\")\n",
        "\n",
        "\n",
        "      if val_perplexity < lowest_perplexity_score:\n",
        "          lowest_perplexity_score = val_perplexity\n",
        "      else:\n",
        "          print(\"The perplexity is higher than the previous epoch, early stop!!!!!!!!!!!!!!!!!!!\")\n",
        "          break\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxbv_a-wdGrf"
      },
      "source": [
        "Now run the training! This part is done for you, but may take time to run, so be patient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8wJej4TdGrg",
        "outputId": "d90e3a20-25d7-4889-c85e-60ab6dfe11b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: lmLSTM(\n",
            "  (embedding): Embedding(20598, 128)\n",
            "  (lstm): LSTM(128, 64, num_layers=2, batch_first=True)\n",
            "  (linear): Linear(in_features=64, out_features=20598, bias=True)\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  20%|██        | 1/5 [1:01:34<4:06:16, 3694.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 0\n",
            "Validation Perplexity: [15.77598193]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "s = time.time()\n",
        "model = training()\n",
        "lstm_time = time.time() - s # Record time\n",
        "test_perplexity = perplexity(test_loader, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24IFCcMVdGrg"
      },
      "source": [
        "### Evaluating the Model\n",
        "Now, plot the perplexity on the eval data against the number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxwnIKZjOuBQ"
      },
      "outputs": [],
      "source": [
        "print(val_pps)\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(val_pps, label='Data Perplexity of Validation Data', color='red')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Data Perplexity')\n",
        "plt.title('Epochs vs.Validation Data Perplexity')\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\", c='0.65')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6J84cZhdGrg"
      },
      "source": [
        "Finally, describe your model architecture, hyperparameters, and experimental procedure. Then, discuss the results you obtained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AqqSh0udGrg"
      },
      "source": [
        "**Model Architecture, Hyperparameters, and Experimental Procedure**\n",
        "\n",
        "\n",
        "The model first starts from an embedding layer.\n",
        "It is responsible for converting discrete tokens (in this case, there are 20598 unique tokens) into continuous vector representations of size 128.\n",
        "\n",
        "Then, the LSTM layer takes the 128-dimensional input from the embedding layer and processes it through two LSTM layers, each with 64 hidden units. The batch_first=True argument means that the input and output tensors are expected to have the batch size as their first dimension.\n",
        "\n",
        "Last followed by the Linear layer. It takes the output of the LSTM layer (which has 64 dimensions) and applies a linear transformation to produce an output of size 20598. This size corresponds to the number of possible output tokens, which is the same as the number of unique tokens in the vocabulary.\n",
        "\n",
        "For the hyperparameters, I set the maxlen as 256, I initially tried 658, which is the maximum length but it runned forever with terrible perplexity. So I tried the mean, but the perplexity is still terrible. so I followed the suggestion on piazza and changed it to 256, and the perplexity becomes normal. These are the examples of the results:\n",
        "\n",
        "maxlen: 256, epoch: 10, perplexity:17 -> 9.7\n",
        "maxlen: 256, epoch: 5, perplexity: 16 -> 10\n",
        "maxlen: 73, epoch:5, perplexity: 332 -> 179\n",
        "\n",
        "The rest of the hyperparameters are:\n",
        "embed_dim = 128\n",
        "\n",
        "hidden_dim = 64\n",
        "\n",
        "num_layers= 2\n",
        "\n",
        "num_epoch = 5 # The maximum training epochs, more epochs are not improving\n",
        "\n",
        "learning_rate = 0.0001\n",
        "\n",
        "The experimental procedure involves data processing by removing punctuations and removing \"<unk>\" , followed by loading data and connected with lstm (2 layers). We keep track of the perplexity of the validation data and also the loss during training to optimize the model.\n",
        "\n",
        "\n",
        "**Results**\n",
        "\n",
        "The reuslts of validation data on perplexity showed that the perplexity is consistently improving. The length of the text affexts a lot how the perplexity was initialed. i.e. 72 max length resulted to 332 perplexity initiallly. And changing to 256 resulted to a more reasonable numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Dp1vSnjZH8d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}